# CommandCenter V2.0 - Product Roadmap

**Vision:** Transform from reactive monitoring to proactive AI-powered energy management
**Timeline:** 3-4 months (Jan - Apr 2026)
**Foundation:** V1.5 (stable) + V1.6 (context management)

---

## Executive Summary

### What V2.0 Delivers

**For Users:**
- Proactive alerts and recommendations (not just Q&A)
- Predictive energy planning (weather + usage patterns)
- Multi-inverter support (SolArk + Victron)
- Custom preferences and policies
- Mobile-optimized dashboard

**For Developers:**
- Unified agent architecture (cleaner, more maintainable)
- Smart context loading (lower costs, faster responses)
- Comprehensive monitoring and observability
- Plugin architecture for easy extensibility
- CI/CD pipeline with automated testing

**For the System:**
- Higher accuracy (95%+ vs current ~70-80%)
- Lower costs (40% reduction in token usage)
- Faster responses (3-5s vs current 5-15s)
- Better reliability (99% uptime target)

---

## V2.0 Feature Matrix

| Feature | V1.5 (Current) | V1.6 (Deploying) | V2.0 (Target) |
|---------|----------------|------------------|---------------|
| **Agent Context** | ‚ùå None | ‚úÖ System specs | ‚úÖ Smart + user prefs |
| **Multi-Turn Memory** | ‚ö†Ô∏è Partial | ‚úÖ Full | ‚úÖ Enhanced + long-term |
| **Proactive Alerts** | ‚ùå None | ‚ùå None | ‚úÖ Full |
| **Inverter Support** | 1 (SolArk) | 1 | 2+ (SolArk + Victron) |
| **Weather Integration** | ‚ùå None | ‚ùå None | ‚úÖ Full |
| **ML Optimization** | ‚ùå None | ‚ùå None | ‚úÖ Basic |
| **User Preferences** | ‚ùå Fixed | ‚ùå Fixed | ‚úÖ Customizable |
| **Mobile UI** | ‚ö†Ô∏è Basic | ‚ö†Ô∏è Basic | ‚úÖ Optimized |
| **Response Time** | 5-15s | 5-15s (target <8s) | 3-5s |
| **Token Usage** | ~3k-5k | ~5k-8k | ~3k-5k (smart loading) |
| **Uptime** | ~95% | ~95% | 99% |

---

## V2.0 Architecture

### High-Level Design

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        V2.0 ARCHITECTURE                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PRESENTATION LAYER                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  ‚îÇ  Web Dash    ‚îÇ  ‚îÇ  Mobile App  ‚îÇ  ‚îÇ  API Clients ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  (Streamlit) ‚îÇ  ‚îÇ  (React)     ‚îÇ  ‚îÇ  (External)  ‚îÇ             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      API GATEWAY LAYER                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  FastAPI + Authentication + Rate Limiting + Caching        ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      AGENT ORCHESTRATION                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Unified Agent Crew (Hierarchical Process)                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Master Agent (Context Manager + Router)            ‚îÇ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - Smart context loading (query-relevant)           ‚îÇ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - User preference integration                       ‚îÇ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - Proactive monitoring coordinator                  ‚îÇ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ                                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ‚îÇ               ‚îÇ            ‚îÇ              ‚îÇ            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇMonitor  ‚îÇ  ‚îÇSolArk   ‚îÇ  ‚îÇVictron   ‚îÇ  ‚îÇEnergy      ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇAgent    ‚îÇ  ‚îÇAgent    ‚îÇ  ‚îÇAgent     ‚îÇ  ‚îÇOptimizer   ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ(NEW)     ‚îÇ  ‚îÇAgent       ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ(Enhanced)‚îÇ ‚îÇ(Enhanced)‚îÇ  ‚îÇ          ‚îÇ  ‚îÇ(Enhanced)  ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       SERVICE LAYER                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇContext Manager‚îÇ  ‚îÇAlert Service   ‚îÇ  ‚îÇML Service        ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ- Smart loading‚îÇ  ‚îÇ- Proactive     ‚îÇ  ‚îÇ- Forecasting     ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ- Caching      ‚îÇ  ‚îÇ- Notifications ‚îÇ  ‚îÇ- Optimization    ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇWeather Service‚îÇ  ‚îÇUser Prefs Mgr  ‚îÇ  ‚îÇTelemetry Collector‚îÇ     ‚îÇ
‚îÇ  ‚îÇ- Forecast API ‚îÇ  ‚îÇ- Per-user      ‚îÇ  ‚îÇ- Multi-source    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ- Integration  ‚îÇ  ‚îÇ- Validation    ‚îÇ  ‚îÇ- Buffering       ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       DATA LAYER                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇPostgreSQL     ‚îÇ  ‚îÇRedis Cache     ‚îÇ  ‚îÇS3/Object Storage ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ+ TimescaleDB  ‚îÇ  ‚îÇ- Context       ‚îÇ  ‚îÇ- Backups         ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ+ pgvector     ‚îÇ  ‚îÇ- Sessions      ‚îÇ  ‚îÇ- Logs            ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   HARDWARE INTEGRATION                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇSolArk API     ‚îÇ  ‚îÇVictron VRM     ‚îÇ  ‚îÇShelly Switches   ‚îÇ      ‚îÇ
‚îÇ  ‚îÇSolark Cloud             ‚îÇ VictronCloudT     ‚îÇ  ‚îÇMiner Control     ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## V2.0 Feature Breakdown

### 1. Unified Agent Architecture (Priority: P0)

**Problem:** Current architecture has 3 separate crews with context loss
**Solution:** Single hierarchical crew with native CrewAI delegation

**Implementation:**
```python
# railway/src/agents/unified_crew.py (NEW)
from crewai import Crew, Process, Agent, Task

def create_unified_crew(query: str, user_id: str = None) -> Crew:
    """Create unified crew with all agents."""

    # Load context smartly
    context_mgr = ContextManager()
    context = context_mgr.get_relevant_context(
        query=query,
        user_id=user_id,
        max_tokens=3000  # Limit to control costs
    )

    # Create all agents
    master = create_master_agent(context)
    monitor = create_monitor_agent(context)
    solark = create_solark_agent(context)
    victron = create_victron_agent(context)  # NEW
    optimizer = create_optimizer_agent(context)

    # Create task for master
    task = create_unified_task(query, context, agent=master)

    return Crew(
        agents=[master, monitor, solark, victron, optimizer],
        tasks=[task],
        process=Process.hierarchical,
        manager_llm="gpt-4-turbo",  # Master uses GPT-4
        verbose=True
    )
```

**Benefits:**
- ‚úÖ Context shared automatically
- ‚úÖ More efficient token usage
- ‚úÖ Better multi-agent coordination
- ‚úÖ Easier to add new agents

**Timeline:** Week 1-2 (2 weeks)

---

### 2. Smart Context Loading (Priority: P0)

**Problem:** Loading all context every request is inefficient
**Solution:** Load only query-relevant context with caching

**Implementation:**
```python
# railway/src/services/context_manager.py (NEW)
from typing import Optional
import redis
from dataclasses import dataclass

@dataclass
class ContextBundle:
    system_context: str      # Hardware, capabilities
    user_context: str        # User preferences
    conversation_context: str # Recent chats
    kb_context: str          # Relevant docs
    total_tokens: int

class ContextManager:
    def __init__(self):
        self.redis = redis.Redis(...)  # Cache
        self.db = get_connection()

    def get_relevant_context(
        self,
        query: str,
        user_id: str = None,
        max_tokens: int = 3000
    ) -> ContextBundle:
        """Get relevant context with caching."""

        # Check cache first
        cache_key = f"context:{user_id}:{hash(query)}"
        if cached := self.redis.get(cache_key):
            return pickle.loads(cached)

        # Build context bundle
        bundle = ContextBundle(
            system_context=self._get_system_context(),  # Always included
            user_context=self._get_user_preferences(user_id),
            conversation_context=self._get_recent_conversations(user_id),
            kb_context=self._get_relevant_kb_docs(query, max_tokens=1000)
        )

        # Cache for 5 minutes
        self.redis.setex(cache_key, 300, pickle.dumps(bundle))

        return bundle
```

**Benefits:**
- ‚úÖ 40% reduction in token usage
- ‚úÖ Faster context loading (cache hit)
- ‚úÖ Scales with more docs
- ‚úÖ Cost-effective

**Timeline:** Week 2-3 (2 weeks)

---

### 3. Proactive Monitoring & Alerts (Priority: P1)

**Problem:** System is purely reactive (waits for user questions)
**Solution:** Background monitoring agent that sends alerts

**Implementation:**
```python
# railway/src/services/proactive_monitor.py (NEW)
from apscheduler.schedulers.background import BackgroundScheduler

class ProactiveMonitor:
    """Background service that monitors system and sends alerts."""

    def __init__(self):
        self.scheduler = BackgroundScheduler()
        self.alert_service = AlertService()

    def start(self):
        """Start background monitoring."""

        # Check battery every 5 minutes
        self.scheduler.add_job(
            self.check_battery_health,
            'interval',
            minutes=5
        )

        # Check solar anomalies every hour
        self.scheduler.add_job(
            self.check_solar_anomalies,
            'interval',
            hours=1
        )

        self.scheduler.start()

    def check_battery_health(self):
        """Monitor battery and send alerts if needed."""
        status = get_current_status()

        # Alert if below minimum
        if status.soc < 30:
            self.alert_service.send(
                level="CRITICAL",
                title="Battery Level Critical",
                message=f"Battery at {status.soc}% (below 30% minimum)",
                actions=["Stop miners", "Enable grid charging"]
            )

        # Alert if discharging rapidly
        if status.batt_power < -5000:  # -5kW = rapid discharge
            self.alert_service.send(
                level="WARNING",
                title="High Battery Discharge",
                message=f"Battery discharging at {abs(status.batt_power)}W",
                context="Check for unexpected loads"
            )
```

**Alert Types:**
- üî¥ **CRITICAL:** Battery <30%, grid outage, system fault
- üü† **WARNING:** Battery <40%, solar underperforming, high load
- üü° **INFO:** Optimization opportunities, maintenance reminders

**Delivery Channels:**
- Dashboard notifications (in-app)
- Email (optional, user pref)
- SMS (critical only, optional)
- Slack/Discord webhook (optional)

**Timeline:** Week 4-5 (2 weeks)

---

### 4. Victron Integration (Priority: P1)

**Problem:** Only supports SolArk inverter
**Solution:** Add Victron Cerbo GX + VRM integration

**Implementation:**
```python
# railway/src/integrations/victron.py (NEW)
import paho.mqtt.client as mqtt
import requests

class VictronClient:
    """Client for Victron Cerbo GX via MQTT and VRM API."""

    def __init__(self, vrm_user_id: str, vrm_token: str):
        self.vrm_user_id = vrm_user_id
        self.vrm_token = vrm_token
        self.mqtt_client = mqtt.Client()

    def get_realtime_data(self) -> dict:
        """Get real-time data via MQTT."""
        # Subscribe to Victron MQTT topics
        # N/[portal ID]/[device instance]/[channel]/[register]
        topics = [
            f"N/{self.vrm_user_id}/system/0/Dc/Battery/Soc",  # SOC
            f"N/{self.vrm_user_id}/system/0/Dc/Battery/Power",  # Battery power
            f"N/{self.vrm_user_id}/system/0/Dc/Pv/Power",  # Solar power
            # ... more topics
        ]
        # ... MQTT subscription logic

    def get_historical_data(self, start: datetime, end: datetime) -> dict:
        """Get historical data via VRM API."""
        url = f"https://vrmapi.victronenergy.com/v2/installations/{self.site_id}/stats"
        response = requests.get(
            url,
            headers={"X-Authorization": f"Bearer {self.vrm_token}"},
            params={"start": start.timestamp(), "end": end.timestamp()}
        )
        return response.json()
```

**New Agent:**
```python
# railway/src/agents/victron_agent.py (NEW)
def create_victron_agent(context: str) -> Agent:
    """Create Victron specialist agent."""
    return Agent(
        role="Victron Energy Systems Specialist",
        goal="Monitor and analyze Victron Cerbo GX + VRM data",
        backstory=f"""You specialize in Victron Energy systems...
        {context}
        """,
        tools=[
            get_victron_status,
            get_victron_historical_data,
            get_victron_settings,
        ],
        verbose=True
    )
```

**Timeline:** Week 6-8 (3 weeks)

---

### 5. Weather Integration & Forecasting (Priority: P2)

**Problem:** No weather data for predictive planning
**Solution:** Integrate weather API for solar forecasting

**Implementation:**
```python
# railway/src/services/weather_service.py (NEW)
import requests
from datetime import datetime, timedelta

class WeatherService:
    """Weather forecast service for solar predictions."""

    def __init__(self, api_key: str, location: tuple):
        self.api_key = api_key
        self.lat, self.lon = location
        self.base_url = "https://api.openweathermap.org/data/3.0/onecall"

    def get_solar_forecast(self, hours: int = 24) -> list[dict]:
        """Get solar irradiance forecast."""
        response = requests.get(
            self.base_url,
            params={
                "lat": self.lat,
                "lon": self.lon,
                "appid": self.api_key,
                "units": "metric"
            }
        )

        data = response.json()
        forecast = []

        for hour in data['hourly'][:hours]:
            # Convert cloud cover to solar estimate
            cloud_cover = hour['clouds']  # 0-100%
            solar_estimate = self._estimate_solar_from_clouds(cloud_cover)

            forecast.append({
                "timestamp": datetime.fromtimestamp(hour['dt']),
                "cloud_cover_pct": cloud_cover,
                "estimated_solar_w": solar_estimate,
                "temp_c": hour['temp']
            })

        return forecast

    def _estimate_solar_from_clouds(self, cloud_cover_pct: float) -> float:
        """Estimate solar production from cloud cover."""
        # Assumes 14.6kW max solar capacity
        max_solar = 14600
        clear_sky_factor = (100 - cloud_cover_pct) / 100
        # Simplified model (real model would use irradiance data)
        return max_solar * clear_sky_factor * 0.8  # 80% efficiency
```

**Use Cases:**
- "Will I have enough solar tomorrow to run miners all day?"
- "What's the forecast for battery charging this week?"
- "Should I charge from grid tonight? (Weather = cloudy tomorrow)"

**Timeline:** Week 8-9 (2 weeks)

---

### 6. ML-Based Optimization (Priority: P2)

**Problem:** Recommendations are rule-based, not predictive
**Solution:** Train ML models on historical data

**Implementation:**
```python
# railway/src/ml/energy_optimizer.py (NEW)
from sklearn.ensemble import RandomForestRegressor
import pandas as pd

class EnergyOptimizer:
    """ML-based energy optimization."""

    def __init__(self):
        self.solar_model = self._load_solar_model()
        self.load_model = self._load_load_model()
        self.battery_model = self._load_battery_model()

    def predict_solar_production(self, hours_ahead: int = 24) -> list[float]:
        """Predict solar production for next N hours."""
        # Features: time of day, day of year, cloud cover, temp
        weather_forecast = self.weather_service.get_solar_forecast(hours_ahead)

        predictions = []
        for forecast in weather_forecast:
            features = self._extract_features(forecast)
            pred = self.solar_model.predict([features])[0]
            predictions.append(pred)

        return predictions

    def recommend_miner_schedule(self) -> dict:
        """Recommend when to run miners based on predictions."""
        solar_forecast = self.predict_solar_production(24)
        load_forecast = self.predict_load(24)

        schedule = []
        for hour, (solar, load) in enumerate(zip(solar_forecast, load_forecast)):
            excess = solar - load

            if excess > 5000:  # 5kW+ excess
                schedule.append({
                    "hour": hour,
                    "action": "run_all_miners",
                    "reason": f"Excess solar: {excess}W"
                })
            elif excess > 1000:
                schedule.append({
                    "hour": hour,
                    "action": "run_2_miners",
                    "reason": f"Some excess: {excess}W"
                })
            else:
                schedule.append({
                    "hour": hour,
                    "action": "stop_miners",
                    "reason": f"Insufficient solar: {excess}W"
                })

        return {"schedule": schedule, "confidence": 0.85}
```

**Models to Train:**
1. **Solar Production Model**
   - Input: time, cloud cover, temp, historical patterns
   - Output: kW production
   - Target Accuracy: 85%+

2. **Load Prediction Model**
   - Input: time, day of week, historical patterns
   - Output: kW consumption
   - Target Accuracy: 80%+

3. **Battery Degradation Model**
   - Input: SOC cycles, charge rates, age
   - Output: capacity loss prediction
   - Target Accuracy: 70%+

**Timeline:** Week 10-12 (3 weeks)

---

### 7. User Preferences & Customization (Priority: P2)

**Problem:** Policies are fixed, not user-specific
**Solution:** Per-user preference system

**Database Schema:**
```sql
-- New table
CREATE TABLE user_preferences (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(100) UNIQUE NOT NULL,

    -- Battery preferences
    min_soc_pct INTEGER DEFAULT 30,
    safe_min_soc_pct INTEGER DEFAULT 40,
    safe_max_soc_pct INTEGER DEFAULT 80,

    -- Miner preferences
    miner_priority VARCHAR(20) DEFAULT 'excess_solar',  -- 'excess_solar', 'always', 'never'
    miner_min_soc_pct INTEGER DEFAULT 50,

    -- Alert preferences
    alerts_enabled BOOLEAN DEFAULT TRUE,
    alert_email VARCHAR(255),
    alert_sms VARCHAR(20),
    alert_critical_only BOOLEAN DEFAULT FALSE,

    -- Display preferences
    timezone VARCHAR(50) DEFAULT 'America/Los_Angeles',
    temp_unit VARCHAR(10) DEFAULT 'fahrenheit',
    power_unit VARCHAR(10) DEFAULT 'watts',

    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

**API Endpoints:**
```python
# railway/src/api/main.py

@app.get("/users/{user_id}/preferences")
def get_user_preferences(user_id: str):
    """Get user preferences."""
    return user_prefs_service.get(user_id)

@app.put("/users/{user_id}/preferences")
def update_user_preferences(user_id: str, prefs: UserPreferences):
    """Update user preferences."""
    return user_prefs_service.update(user_id, prefs)
```

**Timeline:** Week 9-10 (2 weeks)

---

### 8. Mobile-Optimized Dashboard (Priority: P3)

**Problem:** Current Streamlit dashboard not mobile-friendly
**Solution:** React Native mobile app + responsive web

**Tech Stack:**
- **Frontend:** React Native (mobile) + Next.js (web)
- **State:** Redux Toolkit
- **API Client:** Axios with retry logic
- **Push Notifications:** Firebase Cloud Messaging

**Key Screens:**
1. **Home:** Quick metrics (SOC, solar, load)
2. **Detailed:** Charts and historical data
3. **Chat:** Agent conversation interface
4. **Alerts:** Notification center
5. **Settings:** User preferences

**Timeline:** Week 12-16 (4 weeks, parallel track)

---

## Release Plan

### V2.0 Alpha (Week 6) - Internal Testing
- ‚úÖ Unified agent architecture
- ‚úÖ Smart context loading
- ‚úÖ Victron integration (basic)
- ‚ö†Ô∏è Limited to test users

### V2.0 Beta (Week 10) - Limited Rollout
- ‚úÖ Proactive alerts
- ‚úÖ Weather integration
- ‚úÖ User preferences
- ‚ö†Ô∏è Rollout to 10 users

### V2.0 RC (Week 14) - Release Candidate
- ‚úÖ ML optimization (basic)
- ‚úÖ Mobile dashboard (MVP)
- ‚úÖ All features complete
- ‚ö†Ô∏è Performance tuning

### V2.0 GA (Week 16) - General Availability
- ‚úÖ Production ready
- ‚úÖ Documentation complete
- ‚úÖ Support processes in place
- ‚úÖ Marketing materials ready

---

## Migration Path: V1.6 ‚Üí V2.0

### Phase 1: Data Migration (Week 1)
```sql
-- Add new tables
CREATE TABLE user_preferences (...);
CREATE TABLE alert_rules (...);
CREATE TABLE ml_predictions (...);
CREATE TABLE victron_telemetry (...);

-- Migrate existing data
INSERT INTO user_preferences (user_id, ...)
SELECT DISTINCT user_id, ... FROM agent.conversations;
```

### Phase 2: API Compatibility (Week 2-3)
- V1 endpoints remain available
- V2 endpoints added with `/v2/` prefix
- Gradual migration of clients

### Phase 3: Agent Migration (Week 4-6)
- Deploy unified crew alongside old crews
- A/B test (50% traffic to new, 50% to old)
- Monitor performance and accuracy
- Full cutover once validated

### Phase 4: Cleanup (Week 7-8)
- Remove old crew implementations
- Deprecate V1 endpoints
- Archive old code

---

## Success Metrics

### Performance Targets

| Metric | V1.6 Baseline | V2.0 Target | Measurement |
|--------|---------------|-------------|-------------|
| Response Time (p95) | 8s | 5s | API latency |
| Token Usage (avg) | 6k | 4k | OpenAI bills |
| Accuracy | 75% | 95% | User feedback |
| Uptime | 95% | 99% | Monitoring |
| Cost per Query | $0.03 | $0.02 | Token cost |

### User Metrics

| Metric | V1.6 Baseline | V2.0 Target | Measurement |
|--------|---------------|-------------|-------------|
| Daily Active Users | 1 | 10+ | Analytics |
| Queries per Day | 20 | 100+ | API logs |
| User Satisfaction | 3.5/5 | 4.5/5 | Surveys |
| Mobile Usage | 0% | 40%+ | Platform analytics |

### Business Metrics

| Metric | V1.6 | V2.0 Target | Measurement |
|--------|------|-------------|-------------|
| Monthly Cost | $50 | $80 | AWS + OpenAI |
| Energy Savings | Unknown | 10%+ | kWh comparison |
| Miner Uptime | Unknown | 90%+ | Shelly logs |
| Grid Import | Unknown | -20% | SolArk data |

---

## Risk Assessment

### Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| ML models low accuracy | HIGH | MED | Start with rule-based fallback |
| Victron API changes | MED | HIGH | Version pinning + monitoring |
| Token costs explode | MED | HIGH | Smart context + caching |
| Performance degradation | LOW | HIGH | Load testing + monitoring |
| Data loss | LOW | CRITICAL | Automated backups + replication |

### Business Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Low user adoption | MED | MED | Beta testing + feedback |
| Feature creep | HIGH | MED | Strict scope control |
| Budget overrun | MED | MED | Weekly cost tracking |
| Timeline slip | MED | LOW | Buffer time built in |

---

## Resource Requirements

### Development Team
- 1x Senior Backend Engineer (Python/FastAPI)
- 1x ML Engineer (scikit-learn/PyTorch)
- 1x Frontend Engineer (React Native)
- 1x DevOps Engineer (Railway/AWS)
- 0.5x Product Manager
- 0.5x QA Engineer

### Infrastructure
- Railway Pro plan: $50/month
- AWS S3 (backups): $10/month
- OpenAI API (increased): $100/month
- Weather API: $25/month
- Redis Cloud: $15/month
- **Total:** ~$200/month

### Development Timeline
- 16 weeks (4 months)
- ~640 hours (1 FTE for 4 months)

---

## Post-V2.0 Roadmap (V2.1+)

### V2.1 - Advanced Analytics (Month 5-6)
- Energy usage patterns dashboard
- Cost analysis (solar ROI calculator)
- Carbon footprint tracking
- Custom report builder

### V2.2 - Multi-Site Support (Month 7-8)
- Support multiple installations
- Cross-site analytics
- Fleet management dashboard
- Comparative analysis

### V2.3 - Community Features (Month 9-10)
- User forums
- Configuration sharing
- Best practices library
- Peer-to-peer tips

### V3.0 - Enterprise Edition (Month 11-12)
- Multi-tenant architecture
- White-label option
- Advanced RBAC
- SLA guarantees
- Professional support

---

**END OF V2.0 ROADMAP**
