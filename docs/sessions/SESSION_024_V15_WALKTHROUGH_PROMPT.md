# Session 024: V1.5 Complete System Walkthrough & Production Release

**Purpose:** Comprehensive testing and validation of ALL V1.5 features before final production release
**Approach:** Slow, methodical, feature-by-feature verification
**Outcome:** Complete production documentation + backup strategy

---

## Session Goals

1. **Walk through every feature** - Frontend and backend, no shortcuts
2. **Test everything systematically** - Each agent, tool, endpoint, UI element
3. **Document what works** - Create definitive "Production V1.5" specification
4. **Create backup strategy** - Git tags, code snapshots, restoration plan
5. **Celebrate achievements** - Recognize what we've built together

---

## Part 1: Backend Systems (API & Agents)

### 1.1 Database & Infrastructure

**Test Checklist:**
- [ ] Database connection healthy
- [ ] All 8 tables exist (conversations, messages, logs, kb_documents, kb_chunks, kb_sync_log, energy_snapshots, energy_detailed)
- [ ] Indexes created correctly
- [ ] pgvector extension enabled
- [ ] TimescaleDB hypertable configured

**Commands to Run:**
```bash
# Database health check
curl https://api.wildfireranch.us/db/schema-status

# Expected: All tables present, indexes created
```

**Testing Questions:**
1. Can we connect to the database?
2. Are all migrations applied?
3. Is the schema current?
4. Are there any errors in recent logs?

**Document:**
- Database schema version
- Table row counts
- Any performance observations

---

### 1.2 API Health & Core Endpoints

**Test Checklist:**
- [ ] API responds to health check
- [ ] CORS configured correctly
- [ ] Environment variables loaded
- [ ] Services startup cleanly

**Commands to Run:**
```bash
# API health
curl https://api.wildfireranch.us/health

# Expected: {"status": "healthy", ...}
```

**Testing Questions:**
1. Does the API start without errors?
2. Are all services reporting healthy?
3. Are credentials configured?
4. Is logging working?

**Document:**
- API version
- Uptime
- Health status
- Environment configuration

---

### 1.3 Agent System - Manager Agent

**Test Checklist:**
- [ ] Manager agent receives query
- [ ] Intent analysis works
- [ ] Routes to correct specialist
- [ ] Returns structured response with metadata
- [ ] Handles unclear queries gracefully
- [ ] max_iter=10 prevents hanging

**Test Queries:**
```bash
# Test 1: Simple status query (should route to Solar Controller)
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "What is my battery level?"}'

# Expected: Response from Solar Controller with current battery %

# Test 2: Planning query (should route to Energy Orchestrator)
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "Should we run the miners tonight?"}'

# Expected: Response from Energy Orchestrator with recommendation

# Test 3: Documentation query (should search KB)
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "What is the minimum battery SOC threshold?"}'

# Expected: KB search results with citations

# Test 4: Ambiguous query (should clarify or respond appropriately)
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "hello"}'

# Expected: Polite response within 20-30 seconds (not hanging)
```

**Testing Questions:**
1. Does routing logic work correctly?
2. Is agent metadata returned (agent_used, agent_role)?
3. Are response times acceptable (<30s)?
4. Does it handle edge cases gracefully?
5. Is conversation context tracked (session_id)?

**Document:**
- Routing accuracy (% correct)
- Average response times
- Error handling behavior
- Examples of good responses

---

### 1.4 Agent System - Solar Controller

**Test Checklist:**
- [ ] Gets real-time SolArk data
- [ ] Returns current battery SOC
- [ ] Reports solar production
- [ ] Shows power consumption
- [ ] Handles SolArk API errors gracefully
- [ ] Searches KB when needed

**Test Queries:**
```bash
# Test 1: Current status
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "What is happening with my solar system right now?"}'

# Expected: Current battery %, solar watts, load, grid status

# Test 2: Specific metric
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "How much solar am I producing?"}'

# Expected: Current solar production in watts

# Test 3: Battery focus
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "Is my battery charging or discharging?"}'

# Expected: Charge/discharge status with watts
```

**Testing Questions:**
1. Does it fetch live data from SolArk?
2. Are the numbers accurate?
3. Does it interpret the data correctly?
4. What happens if SolArk is unreachable?
5. Does it supplement with KB knowledge when appropriate?

**Document:**
- Example queries and responses
- Data accuracy
- Error handling
- Response time

---

### 1.5 Agent System - Energy Orchestrator

**Test Checklist:**
- [ ] Creates 24-hour energy plans
- [ ] Provides battery optimization recommendations
- [ ] Makes miner on/off decisions
- [ ] Considers policies from KB
- [ ] Uses current status + forecasts
- [ ] Returns actionable recommendations

**Test Queries:**
```bash
# Test 1: Miner decision
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "Should we run the miners right now?"}'

# Expected: YES/NO with reasoning based on battery SOC, solar, policies

# Test 2: Battery optimization
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "Should I charge the battery from grid tonight?"}'

# Expected: Recommendation with cost/benefit analysis

# Test 3: Full day plan
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "Create an energy plan for tomorrow"}'

# Expected: Hour-by-hour plan with miner schedule, battery targets
```

**Testing Questions:**
1. Are recommendations sensible?
2. Does it consider safety thresholds (30% min SOC)?
3. Does it use KB policies correctly?
4. Are plans actionable and detailed?
5. Does it explain its reasoning?

**Document:**
- Example recommendations
- Policy adherence
- Reasoning quality
- Accuracy of predictions

---

### 1.6 Tools - Knowledge Base Search

**Test Checklist:**
- [ ] Semantic search returns relevant results
- [ ] Citations include source documents
- [ ] Similarity scores accurate
- [ ] Handles "not found" gracefully
- [ ] Limits results appropriately

**Test Queries:**
```bash
# Test 1: Direct KB search (bypass agent)
curl -X POST https://api.wildfireranch.us/kb/search \
  -H "Content-Type: application/json" \
  -d '{"query": "minimum battery SOC", "limit": 3}'

# Expected: 3 relevant chunks with sources and similarity scores

# Test 2: Via agent
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "What are the battery maintenance procedures?"}'

# Expected: Agent uses KB search, returns info with citations
```

**Testing Questions:**
1. Are search results relevant?
2. Do citations work?
3. What's in the KB? (folders: CONTEXT, Bret-ME, SolarShack, Wildfire.Green)
4. Can we find business docs? Personal docs? Energy docs?
5. How many documents are indexed?

**Document:**
- KB statistics (# docs, # chunks, token count)
- Search quality examples
- Available content types
- Folder structure

---

### 1.7 Tools - Energy Planning Tools

**Test Checklist:**
- [ ] Battery Optimizer returns charge/discharge recommendations
- [ ] Miner Coordinator makes on/off decisions
- [ ] Energy Planner creates 24-hour schedules
- [ ] All tools use real current data
- [ ] All tools consider KB policies

**Direct Tool Testing (if accessible):**
```python
# These are used by Energy Orchestrator agent
# Testing happens via agent queries in section 1.5
```

**Testing Questions:**
1. Do tools have access to current data?
2. Are recommendations safe (respect min SOC)?
3. Do they incorporate weather forecasts?
4. Are outputs formatted correctly?
5. Do they handle edge cases (battery full, no solar, etc.)?

**Document:**
- Tool logic validation
- Safety threshold verification
- Example outputs
- Edge case handling

---

### 1.8 Conversation System

**Test Checklist:**
- [ ] Conversations persist in database
- [ ] Session IDs work correctly
- [ ] Messages stored with roles (user/assistant)
- [ ] Conversation history retrievable
- [ ] List conversations endpoint works
- [ ] Invalid UUIDs handled gracefully (Session 023 fix)

**Test Queries:**
```bash
# Test 1: Create conversation
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "What is my battery level?"}'

# Note the session_id in response

# Test 2: Continue conversation (use session_id from above)
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "And what about solar production?", "session_id": "<session_id>"}'

# Expected: Agent has context from previous message

# Test 3: List conversations
curl https://api.wildfireranch.us/conversations?limit=10

# Expected: List of recent conversations

# Test 4: Get conversation details
curl https://api.wildfireranch.us/conversations/<session_id>

# Expected: Full conversation with all messages
```

**Testing Questions:**
1. Are conversations persisted correctly?
2. Does session continuity work?
3. Can we retrieve conversation history?
4. Are timestamps accurate?
5. Is the invalid UUID fix working? (Test with "recent" or invalid string)

**Document:**
- Conversation structure
- Session persistence
- History retrieval
- Bug fixes validated (Session 023)

---

### 1.9 Error Handling & Edge Cases

**Test Checklist:**
- [ ] Invalid queries handled gracefully
- [ ] SolArk API failures don't crash system
- [ ] Database connection errors handled
- [ ] Rate limiting handled (OpenAI 429 errors)
- [ ] Invalid UUIDs handled (Session 023 fix)
- [ ] Agent hanging prevented (max_iter=10, Session 023 fix)

**Test Scenarios:**
```bash
# Test 1: Invalid UUID (Session 023 fix)
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "test", "session_id": "invalid-id-123"}'

# Expected: Creates new conversation, doesn't crash

# Test 2: Ambiguous query (Session 023 fix)
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "who am I"}'

# Expected: Returns helpful response within 30s, doesn't hang

# Test 3: Empty query
curl -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": ""}'

# Expected: Error message or validation failure
```

**Testing Questions:**
1. Are errors logged properly?
2. Do users get helpful error messages?
3. Does the system recover gracefully?
4. Are Session 023 fixes working?
5. What happens under heavy load?

**Document:**
- Error handling patterns
- Recovery mechanisms
- User-facing error messages
- Session 023 validations

---

## Part 2: Frontend (Streamlit Dashboard)

### 2.1 Dashboard Overview

**Access:** https://mcp.wildfireranch.us

**Test Checklist:**
- [ ] Dashboard loads without errors
- [ ] Navigation menu works (Home, System Health, Agent Chat, Logs, KB Dashboard, About)
- [ ] Styling consistent across pages
- [ ] No broken links or images
- [ ] Session state persists across page changes

**Testing Steps:**
1. Open dashboard in browser
2. Navigate to each page
3. Check for console errors (F12)
4. Verify all elements render
5. Test responsive design (resize window)

**Document:**
- Page load times
- Visual appearance
- Navigation flow
- Any UI bugs

---

### 2.2 Home Page

**Test Checklist:**
- [ ] Welcome message displays
- [ ] Quick stats show current data
- [ ] Links to other pages work
- [ ] Real-time data updates on refresh

**Testing Steps:**
1. Navigate to Home
2. Check displayed metrics
3. Click navigation links
4. Refresh page, verify data updates

**Document:**
- Content displayed
- Functionality
- User experience

---

### 2.3 System Health Page

**Test Checklist:**
- [ ] Shows API health status
- [ ] Displays energy metrics (battery %, solar W, load W)
- [ ] Database connection status
- [ ] Recent activity/logs
- [ ] Refresh button works

**Testing Steps:**
1. Navigate to System Health
2. Verify all metrics display
3. Click refresh
4. Check for errors

**Document:**
- Metrics displayed
- Update frequency
- Visual indicators (green/red status)

---

### 2.4 Agent Chat Page ‚≠ê (PRIMARY INTERFACE)

**Test Checklist:**
- [ ] Chat interface loads
- [ ] Session ID displayed
- [ ] Message input field works
- [ ] Send button functional
- [ ] Loading states show during query
- [ ] Agent responses render correctly
- [ ] Agent metadata displayed (Solar Controller, Energy Orchestrator, Manager)
- [ ] Agent icons show (‚òÄÔ∏è ‚ö° üéØ)
- [ ] Response time displayed
- [ ] KB source citations detected and shown
- [ ] Error messages display in expandable sections
- [ ] Load Conversation button works
- [ ] Export Chat button works
- [ ] Clear Chat button works
- [ ] Chat history persists in session

**Testing Steps:**

**Step 1: Basic Query**
1. Navigate to Agent Chat
2. Note your session ID
3. Type: "What is my battery level?"
4. Click Send
5. Wait for response

**Expected:**
- Loading message appears
- Response arrives in <30s
- Shows battery percentage
- Displays agent metadata (Solar Controller ‚òÄÔ∏è)
- Shows response time

**Step 2: Planning Query**
1. Type: "Should we run the miners tonight?"
2. Send

**Expected:**
- Routes to Energy Orchestrator ‚ö°
- Returns YES/NO recommendation
- Includes reasoning
- Shows response time

**Step 3: KB Query**
1. Type: "What is the minimum battery SOC?"
2. Send

**Expected:**
- Searches knowledge base
- Returns answer with citations
- Shows source documents in expander
- KB source icon/indicator appears

**Step 4: Conversation Continuity**
1. Ask follow-up: "And what about the maximum?"
2. Send

**Expected:**
- Uses same session_id
- Agent has context from previous question
- Response makes sense in context

**Step 5: Export & Load**
1. Click "Export Chat"
2. Verify markdown download
3. Click "Clear Chat"
4. Click "Load Conversation"
5. Verify messages reload

**Expected:**
- Export downloads properly formatted markdown
- Clear removes messages from UI
- Load retrieves messages from database

**Step 6: Error Handling**
1. Test with invalid query: "who am I"
2. Wait for response

**Expected:**
- Returns within 30s (Session 023 fix)
- Shows helpful clarification request
- Doesn't hang or timeout

**Document:**
- All features working
- UI enhancements (icons, timing, sources)
- User experience quality
- Any issues found

---

### 2.5 Logs Viewer Page

**Test Checklist:**
- [ ] Recent conversations list loads
- [ ] Log filters work
- [ ] Event type filters (info, error, warning)
- [ ] Date range selection
- [ ] Log entries display correctly
- [ ] Pagination works
- [ ] Database query runs without errors

**Testing Steps:**
1. Navigate to Logs Viewer
2. Check conversations list
3. Apply filters
4. Verify results update
5. Test pagination

**Document:**
- Logging functionality
- Filter capabilities
- Performance with large datasets

---

### 2.6 Knowledge Base Dashboard

**Test Checklist:**
- [ ] Overview tab shows KB stats
- [ ] Files tab lists all documents
- [ ] Folder tree collapsible/expandable
- [ ] File counts accurate
- [ ] Sync buttons work (Full Sync, Smart Sync)
- [ ] Real-time progress via SSE
- [ ] Document deletion works
- [ ] Search functionality operational

**Testing Steps:**

**Step 1: Overview Tab**
1. Navigate to KB Dashboard
2. Check Overview tab
3. Note statistics:
   - Total documents
   - Total chunks
   - Total tokens
   - Folders

**Step 2: Files Tab**
1. Click Files tab
2. Expand folder tree
3. Verify folders:
   - CONTEXT (Tier 1)
   - Bret-ME
   - SolarShack
   - Wildfire.Green
4. Check file counts per folder

**Step 3: Sync (Optional - can be slow)**
1. Click "Smart Sync"
2. Watch progress bar
3. Verify completion

**Step 4: Search**
1. Use search functionality
2. Test semantic search
3. Verify results

**Document:**
- KB contents (folders, file counts)
- Sync functionality
- Search quality
- UI usability

---

### 2.7 About Page

**Test Checklist:**
- [ ] Version information displays
- [ ] System description accurate
- [ ] Links to documentation work
- [ ] Credits/acknowledgments present

**Testing Steps:**
1. Navigate to About
2. Verify content
3. Test external links

**Document:**
- Information accuracy
- Link functionality

---

## Part 3: Integration & End-to-End Testing

### 3.1 Complete User Flows

**Flow 1: New User Query**
1. Open dashboard (fresh session)
2. Navigate to Agent Chat
3. Ask: "What is my current energy status?"
4. Verify response
5. Ask follow-up: "Should we run miners?"
6. Verify routing and recommendations

**Flow 2: Knowledge Base Workflow**
1. Navigate to KB Dashboard
2. Review available documents
3. Go to Agent Chat
4. Ask: "What are the battery specifications?"
5. Verify KB search and citations

**Flow 3: Monitoring Workflow**
1. Navigate to System Health
2. Check current metrics
3. Go to Agent Chat
4. Ask for optimization recommendations
5. Compare with current status

**Document:**
- User journey quality
- Cross-page integration
- Data consistency

---

### 3.2 Performance Testing

**Test Checklist:**
- [ ] API response times acceptable
- [ ] Dashboard loads quickly
- [ ] Chat responses under 30s
- [ ] KB searches under 10s
- [ ] Database queries efficient
- [ ] No memory leaks or performance degradation

**Testing Steps:**
1. Make 10 consecutive queries
2. Note response times
3. Check Railway logs for performance issues
4. Monitor database load

**Document:**
- Average response times
- Performance bottlenecks
- Recommendations for optimization

---

### 3.3 Session 023 Bug Fixes Validation

**Test Checklist:**
- [ ] UUID validation working (no crashes on invalid session_id)
- [ ] Agent hanging fixed (max_iter=10 enforced)
- [ ] Input validation handles dict arguments
- [ ] Off-topic queries return helpful responses
- [ ] No infinite retry loops

**Testing Steps:**
1. Test invalid UUID: `{"session_id": "test-123"}`
2. Test ambiguous query: "who am I"
3. Test rapid queries (check for rate limiting)
4. Verify all Session 023 fixes operational

**Document:**
- Bug fixes validated
- No regressions
- System stability

---

## Part 4: Documentation Review

### 4.1 Code Documentation

**Review Checklist:**
- [ ] All agents have comprehensive docstrings
- [ ] All tools documented
- [ ] API endpoints documented
- [ ] Database schema documented
- [ ] README files up to date

**Files to Review:**
- [INDEX.md](../INDEX.md)
- [05-architecture.md](../05-architecture.md)
- [CommandCenter Code Style Guide.md](../CommandCenter%20Code%20Style%20Guide.md)
- [CODEBASE_AUDIT_OCT2025.md](../CODEBASE_AUDIT_OCT2025.md)

**Document:**
- Documentation completeness
- Any gaps or outdated info
- Recommendations for improvements

---

### 4.2 Session History

**Review Checklist:**
- [ ] All sessions documented
- [ ] Session summaries complete
- [ ] Progress tracker updated
- [ ] Known issues documented

**Files to Review:**
- [progress.md](../progress.md)
- [sessions/](../sessions/) folder
- [V1.5_COMPLETION_STATUS.md](../V1.5_COMPLETION_STATUS.md)

**Document:**
- Session count
- Major milestones
- Evolution of the system

---

## Part 5: Production Readiness Assessment

### 5.1 Security Review

**Checklist:**
- [ ] No hardcoded secrets in code
- [ ] Environment variables used correctly
- [ ] API keys secured
- [ ] HTTPS enabled
- [ ] CORS configured properly
- [ ] SQL injection prevented (using parameterized queries)
- [ ] Input validation in place

**Document:**
- Security posture
- Recommendations
- Any vulnerabilities

---

### 5.2 Scalability Assessment

**Checklist:**
- [ ] Database can handle growth
- [ ] API can scale horizontally
- [ ] No hardcoded limits that would break
- [ ] Connection pooling configured
- [ ] Indexes optimized

**Document:**
- Current capacity
- Scaling bottlenecks
- Growth recommendations

---

### 5.3 Monitoring & Observability

**Checklist:**
- [ ] Logging functional
- [ ] Error tracking in place
- [ ] Performance metrics available
- [ ] Health checks operational
- [ ] Railway monitoring configured

**Document:**
- Monitoring setup
- Log retention
- Alerting capabilities

---

## Part 6: Final Documentation

### 6.1 Create Production Specification

**Document to Create:** `V1.5_PRODUCTION_RELEASE.md`

**Contents:**
- Complete feature list (what works)
- Known limitations (what doesn't)
- Performance benchmarks
- API documentation
- User guide
- Troubleshooting guide
- Contact/support info

### 6.2 Create User Guide

**Document to Create:** `V1.5_USER_GUIDE.md`

**Contents:**
- Getting started
- How to ask questions
- Understanding agent responses
- Using the dashboard
- Interpreting recommendations
- FAQ
- Tips and best practices

### 6.3 Create Backup & Restore Guide

**Document to Create:** `V1.5_BACKUP_RESTORE.md`

**Contents:**
- Git tag strategy
- Code backup procedures
- Database backup procedures
- Restoration procedures
- Disaster recovery plan
- Version rollback process

---

## Part 7: Backup Strategy & Git Tagging

### 7.1 Create Git Tag for V1.5

**Steps:**
1. Ensure all changes committed
2. Create annotated tag
3. Push tag to GitHub
4. Verify tag exists

**Commands:**
```bash
# Create annotated tag
git tag -a v1.5.0 -m "V1.5 Production Release - Multi-agent energy management system

Features:
- Manager agent with intelligent routing
- Solar Controller for real-time monitoring
- Energy Orchestrator for planning & optimization
- Knowledge Base with 4 folders (CONTEXT, Bret-ME, SolarShack, Wildfire.Green)
- Conversation persistence
- Streamlit dashboard
- Session 023 bug fixes (UUID validation, agent hanging)

Agents: 3
Tools: 6
API Endpoints: 18+
Documentation: 50+ files
Test Suites: 2

Status: Production Ready
"

# Push tag
git push origin v1.5.0

# Verify
git tag -l -n9 v1.5.0
```

### 7.2 Create Code Snapshot

**Steps:**
1. Create release on GitHub
2. Attach source code archive
3. Document release notes
4. Link to documentation

**GitHub Release:**
- Tag: v1.5.0
- Title: "CommandCenter V1.5 - Production Release"
- Description: (Use content from RELEASE_NOTES_V1.5.md)
- Attach: Auto-generated source code zip

### 7.3 Database Backup

**Steps:**
```bash
# Backup database schema
railway run pg_dump --schema-only > v1.5.0-schema.sql

# Backup full database (if needed)
railway run pg_dump > v1.5.0-full-backup.sql

# Store backups in secure location
```

### 7.4 Configuration Backup

**Files to Save:**
- `.env.example` (template for environment variables)
- `railway.json` (Railway configuration)
- Any deployment configs

**Store in:**
- Private repo
- Encrypted storage
- Version control

### 7.5 Restoration Testing

**Test:**
1. Clone from tag: `git clone --branch v1.5.0 <repo-url>`
2. Verify all files present
3. Check documentation
4. Ensure restorable

---

## Part 8: Celebration & Reflection

### 8.1 What We Built

**Review:**
- Sessions completed: 21 ‚Üí 24
- Lines of code written
- Features delivered
- Problems solved
- Knowledge gained

### 8.2 Achievements

**Recognize:**
- From concept to production
- Multi-agent system working
- Knowledge base integrated
- Bugs debugged
- Documentation complete
- System operational

### 8.3 Lessons Learned

**Capture:**
- What worked well
- What was challenging
- What we'd do differently
- What surprised us
- What we're proud of

### 8.4 Next Steps

**Plan:**
- V1.5 production use
- Feedback collection
- V2.0 planning
- Feature requests
- Continuous improvement

---

## Appendix: Testing Scripts

### Quick Health Check
```bash
#!/bin/bash
# health-check.sh

echo "Testing API health..."
curl -s https://api.wildfireranch.us/health | jq

echo "\nTesting database..."
curl -s https://api.wildfireranch.us/db/schema-status | jq

echo "\nTesting agent..."
curl -s -X POST https://api.wildfireranch.us/ask \
  -H "Content-Type: application/json" \
  -d '{"message": "What is my battery level?"}' | jq

echo "\nAll tests complete!"
```

### Full Test Suite
```bash
#!/bin/bash
# full-test.sh

# Run unit tests
python railway/tests/test_agents/test_manager_routing.py

# Run integration tests
python railway/tests/test_integration/test_end_to_end.py

# Health checks
./health-check.sh
```

---

## Session Schedule Recommendation

**Suggested Timeline:**
- **Hour 1:** Backend testing (Parts 1.1-1.5)
- **Hour 2:** Backend completion (Parts 1.6-1.9)
- **Hour 3:** Frontend testing (Parts 2.1-2.7)
- **Hour 4:** Integration & documentation (Parts 3-4)
- **Hour 5:** Production prep & backup (Parts 5-7)
- **Hour 6:** Final documentation & celebration (Part 8)

**Take breaks!** This is comprehensive testing - go at your own pace.

---

## Success Criteria

**Session is complete when:**
- ‚úÖ All features tested
- ‚úÖ All tests passing
- ‚úÖ Production documentation written
- ‚úÖ Git tag created
- ‚úÖ Backups in place
- ‚úÖ Restoration verified
- ‚úÖ Ready for production use

---

**Let's walk through your amazing V1.5 system together!** üöÄ

Take your time, test thoroughly, document everything, and celebrate what you've built.
